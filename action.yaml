---
# https://docs.github.com/en/actions/sharing-automations/creating-actions/creating-a-composite-action
name: 'Nested VMs'
description: 'Standup a cluster of nested virtual machines using libvirt.'

inputs:
  os:
    description: 'Operating system to use for the cluster.'
    required: true
  os-version:
    description: 'Operating system version to use for the cluster.'
    required: true
  os-arch:
    description: 'Operating system arch to use for the cluster.'
    required: true
  image_version:
    description: |-
      Specific image version to download. If not specified, then
      the latest released os-version image will be downloaded.

      Examples:
        * Debian
          - daily-latest (use this for the latest pre-release version)
          - daily-YYYYMMDD-\d\d\d\d
          - YYYYMMDD-\d\d\d\d
        * Ubuntu
          - YYYYMMDD

      Note that there is no guarantee a given image version exists,
      you will need to check the image server. See
      [kvm_automation_tooling::get_image_url()](https://github.com/jpartlow/kvm_automation_tooling/blob/main/functions/get_image_url.pp)
      for details of how image urls are constructed.
  image_url_override:
    description: |-
      If specified, this will override the image_url generated by
      kvm_automation_tooling::get_image_url() entirely.
  ruby-version:
    description: 'Ruby version to install for the action.'
    required: true
    default: '3.3'
  vms:
    description: |-
      JSON array of VM definitions as defined by the
      [kvm_automation_tooling::vm_spec](https://github.com/jpartlow/kvm_automation_tooling/blob/main/types/vm_spec.pp)
      datatype.
    required: true
    default: |-
      [
        {
          "role": "agent"
        }
      ]
  install-openvox:
    description: |-
      Whether or not to install the openvox Puppet(TM) agent on the
      vms.
    default: false
  openvox-collection:
    default: 'openvox8'
  openvox-version:
    description: |-
      Version of openvox to install in the cluster. The default value,
      'latest', will install the latest version of openvox in the
      given openvox-collection. The openvox-version must match the
      collection (you can't request 7.y from the openvox8
      collection...).

      If you are installing a pre-release version of openvox, then
      openvox-collection is ignored and openvox-version must be a
      specific version, not 'latest'.
    default: 'latest'
  openvox-released:
    description: |-
      If true, install a released openvox-version from the set
      openvox-collection. If false, install a pre-release
      openvox-version package from the openvox-artifacts-url server.
    default: true
  openvox-artifacts-url:
    description: |-
      URL to the openvox build artifacts. Used to download pre-release
      openvox rpm or deb packages directly, if openvox-released is set
      to false.
    default: 'https://artifacts.voxpupuli.org'
  setup-cluster-ssh:
    description: |-
      If true, generated VMs with controller roles ('primary' or
      'runner'), will be given ssh access to all vms in the cluster.
    default: true
  setup-cluster-root-ssh:
    description: |-
      If true, and setup-cluster-ssh is true, controllers will
      also be given root ssh access.
    default: false
  host-root-access:
    description: |-
      If true, the generated VMs will be configured to allow the
      host root access via SSH.
    default: false
  debug:
    description: 'Enable debug output (adds --stream to bolt commands).'
    default: false
  checkout:
    description: |-
      Checkout the kvm_automation_tooling module from GitHub.

      This can be set to false to instead use the
      kvm_automation_tooling/ checkout provided by the calling
      workflow.
    default: true
  cluster_id:
    description: |-
      The cluster ID to use for the generated VMs. This is used to
      distinguish the VM hostnames, Terraform domains, Bolt inventory
      and Terraform state files.
    default: test
  network_prefix:
    description: |-
      The first three octects of the network address range to use for
      the generated libvirt network. The actual range in CIDR notation
      will be 'A.B.C.0/24'. The gateway address will be 'A.B.C.1'.
    default: "192.168.100"
  domain_name:
    description: |-
      The domain name for the guest cluster.
    default: vm
  ssh_key_name:
    description: |-
      The name of the SSH key to use for ssh access to cluster vms. If
      the file ~/.ssh/<ssh_key_name> does not exist, it will be
      generated as an ed25519 key.
    default: ssh-id-test

outputs:
  cluster-details:
    description: "VM information for the cluster (ip and hostname)."
    value: ${{ steps.inventory-details.outputs.inventory_json }}

env:
  # Suppress warnings about Bolt gem versus package use.
  BOLT_GEM: true

runs:
  using: "composite"
  steps:
    - name: Checkout kvm_automation_tooling module
      if: ${{ inputs.checkout == 'true' }}
      uses: actions/checkout@v5
      with:
        repository: 'jpartlow/kvm_automation_tooling'
        ref: 'v2'
        path: 'kvm_automation_tooling'
    - name: Install Terraform
      shell: bash
      run: |-
        # From https://developer.hashicorp.com/terraform/install
        wget -O - https://apt.releases.hashicorp.com/gpg | \
          sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
        echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | \
          sudo tee /etc/apt/sources.list.d/hashicorp.list
        sudo apt update && sudo apt install terraform
    - name: Install Libvirt
      shell: bash
      run: |-
        sudo apt install libvirt-daemon-system libvirt-dev genisoimage
        # Even if we add the runner user to the libvirt group, we can't
        # restart the session to take advantage of that, and using
        # something like newgrp requests a password, while su -l also
        # fails to provide a shell with the new group membership. So I'm
        # just opening up permissions instead.
        sudo chmod o+rw /var/run/libvirt/libvirt-sock
        # Turn off the qemu security driver to avoid SELinux issues reading
        # the base image file.
        sudo sed -i -e 's/^#security_driver =.*$/security_driver = "none"/' '/etc/libvirt/qemu.conf'
        sudo systemctl restart libvirtd
        # Create the default directory storage pool.
        sudo virsh pool-create-as --name default --type dir --target /var/lib/libvirt/images
    - uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ inputs.ruby-version }}
        bundler-cache: true
        working-directory: kvm_automation_tooling
    - name: Install module dependencies
      shell: bash
      working-directory: kvm_automation_tooling
      run: bundle exec bolt module install
    - name: Generate an SSH key to use for the cluster
      shell: bash
      env:
        SSH_KEY_NAME: ${{ inputs.ssh_key_name }}
      run: |-
        if [ ! -f "${HOME}/.ssh/${SSH_KEY_NAME}" ]; then
          echo "Generating SSH key ${SSH_KEY_NAME} in ${HOME}/.ssh"
          ssh-keygen -t ed25519 -f "${HOME}/.ssh/${SSH_KEY_NAME}" -N '' -q
        else
          echo "Using existing SSH key ${SSH_KEY_NAME} in ${HOME}/.ssh"
          cat "${HOME}/.ssh/${SSH_KEY_NAME}.pub"
        fi
    - name: Write standup_cluster params
      shell: bash
      env:
        OS: ${{ inputs.os }}
        OS_VERSION: ${{ inputs.os-version }}
        OS_ARCH: ${{ inputs.os-arch }}
        IMAGE_VERSION: ${{ inputs.image_version && format('"{0}"', inputs.image_version) || 'null' }}
        IMAGE_URL_OVERRIDE: ${{ inputs.image_url_override && format('"{0}"', inputs.image_url_override) || 'null' }}
        VMS: ${{ inputs.vms }}
        SETUP_CLUSTER_SSH: ${{ inputs.setup-cluster-ssh }}
        SETUP_CLUSTER_ROOT_SSH: ${{ inputs.setup-cluster-root-ssh }}
        HOST_ROOT_ACCESS: ${{ inputs.host-root-access }}
        INSTALL_OPENVOX: ${{ inputs.install-openvox }}
        OPENVOX_COLLECTION: ${{ inputs.openvox-collection || 'openvox8' }}
        OPENVOX_VERSION: ${{ inputs.openvox-version || 'latest' }}
        OPENVOX_RELEASED: ${{ inputs.openvox-released }}
        OPENVOX_ARTIFACTS_URL: ${{ inputs.openvox-artifacts-url }}
        CLUSTER_ID: ${{ inputs.cluster_id }}
        NETWORK_ADDRESSES: ${{ format('{0}.0/24', inputs.network_prefix) }}
        DOMAIN_NAME: ${{ inputs.domain_name }}
        SSH_KEY_NAME: ${{ inputs.ssh_key_name }}
      working-directory: kvm_automation_tooling
      run: |-
        cat > standup_cluster_params.json <<EOF
        {
          "cluster_id": "${CLUSTER_ID}",
          "network_addresses": "${NETWORK_ADDRESSES}",
          "domain_name": "${DOMAIN_NAME}",
          "ssh_public_key_path": "${HOME}/.ssh/${SSH_KEY_NAME}.pub",
          "setup_cluster_ssh": ${SETUP_CLUSTER_SSH},
          "setup_cluster_root_ssh": ${SETUP_CLUSTER_ROOT_SSH},
          "host_root_access": ${HOST_ROOT_ACCESS},
          "os": "${OS}",
          "os_version": "${OS_VERSION}",
          "os_arch": "${OS_ARCH}",
          "image_version": ${IMAGE_VERSION},
          "image_url_override": ${IMAGE_URL_OVERRIDE},
          "vms": ${VMS},
          "install_openvox": ${INSTALL_OPENVOX},
          "install_openvox_params": {
            "openvox_agent_params": {
              "openvox_collection": "${OPENVOX_COLLECTION}",
              "openvox_version": "${OPENVOX_VERSION}",
              "openvox_released": ${OPENVOX_RELEASED},
              "openvox_artifacts_url": "${OPENVOX_ARTIFACTS_URL}"
            },
            "install_defaults": {
              "openvox_version": "latest",
              "openvox_collection": "${OPENVOX_COLLECTION}",
              "openvox_released": true
            }
          }
        }
        EOF
        cat standup_cluster_params.json
    - name: Run standup_cluster plan
      shell: bash
      env:
        STREAM: ${{ ((inputs.debug == 'true') && '--stream --no-verbose') || '' }}
      working-directory: kvm_automation_tooling
      run: |-
        bundle exec bolt plan run kvm_automation_tooling::standup_cluster --params @standup_cluster_params.json ${STREAM}
    # This will allow the runner to resolve guest fqdn like
    # 'test-agent-1.vm'. The actual hostnames depend on the
    # inputs.cluster_id and inputs.vms roles. See
    # kvm_automation_tooling for details.
    - name: Add resolver for cluster domain
      shell: bash
      env:
        CLUSTER_RESOLVED_CONF: ${{ format('{0}-cluster-domain.conf', inputs.cluster_id) }}
        GATEWAY_IP: ${{ format('{0}.1', inputs.network_prefix) }}
        DOMAIN_NAME: ${{ inputs.domain_name }}
      run: |-
        resolved_conf="/etc/systemd/resolved.conf.d/${CLUSTER_RESOLVED_CONF}"
        sudo mkdir -p /etc/systemd/resolved.conf.d
        sudo touch "${resolved_conf}"
        sudo chmod 644 "${resolved_conf}"
        sudo chown "${USER}:${USER}" "${resolved_conf}"
        cat > "${resolved_conf}" <<EOF
        [Resolve]
        DNS=${GATEWAY_IP}
        Domains=~${DOMAIN_NAME}
        EOF
        cat "${resolved_conf}"
        sudo systemctl restart systemd-resolved
    - name: Collect inventory details
      id: inventory-details
      shell: bash
      env:
        CLUSTER_ID: ${{ inputs.cluster_id }}
      working-directory: kvm_automation_tooling
      run: |-
        bundle exec bolt inventory show --inventory terraform/instances/inventory.${CLUSTER_ID}.yaml --format json --detail | tee inventory.json
        echo "inventory_json=$(cat inventory.json)" >> $GITHUB_OUTPUT
